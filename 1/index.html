<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Project 1 — Prokudin-Gorskii Colorizing</title>
  <meta name="theme-color" content="#ffffff"/>
  <style>
    body {
      font-family: "Roboto", sans-serif;
      background: #f9fafb;
      color: #1f2937;
      margin: 0;
      line-height: 1.6;
    }
    header {
      background: #2563eb;
      color: white;
      padding: 1rem 2rem;
    }
    main {
      max-width: 900px;
      margin: 2rem auto;
      padding: 0 1rem;
    }
    h2 {
      border-bottom: 2px solid #e5e7eb;
      padding-bottom: 0.3rem;
    }
    section {
      margin-bottom: 2.5rem;
    }
    .result {
      display: flex;
      gap: 1rem;
      background: white;
      padding: 1rem;
      border-radius: 12px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
      margin-bottom: 1.5rem;
      align-items: center;
    }
    .result img {
      width: 220px;
      border-radius: 8px;
    }
    footer {
      text-align: center;
      color: #6b7280;
      font-size: 0.9rem;
      padding: 1rem;
      border-top: 1px solid #e5e7eb;
      background: #f3f4f6;
    }
  </style>
</head>
<body>
<header>
  <h1>Project 1 — Colorizing the Prokudin-Gorskii Collection</h1>
</header>

<main>
  <section>
    <h2>Overview</h2>
    <p>
      The goal of this project is to take the digitized Prokudin-Gorskii glass plate images and automatically produce a color image.
      The input is a single grayscale plate stacked vertically in the order <strong>B, G, R</strong>.
      I split the image into three equal parts, then align the <em>G</em> and <em>R</em> channels to <em>B</em>.
    </p>
  </section>

  <section>
    <h2>Single-Scale Alignment</h2>
    <p>
      As a baseline, I implemented single-scale alignment using NCC. This method worked surprisingly well after pre-processes the image. The idea is first pre-process the image (see bells&whistles section), then within the [-15,15] pixel range, find the best alignment such that the NCC value is maximized. Blue is used as a reference picture while green and red are moved with (x,y) pixels to align with blue.
    </p>
    <div class="result"> 
      <img src="output/cathedral.jpg" alt="cathedral"/> 
      <div><strong>cathedral</strong><br>Green offset: (+2, +5)<br>Red offset: (+3, +12)</div> 
    </div>
    <div class="result"> 
      <img src="output/monastery.jpg" alt="monastery"/> 
      <div><strong>monastery</strong><br>Green offset: (+2, -3)<br>Red offset: (+2, +3)</div> 
    </div>
    <div class="result"> 
      <img src="output/tobolsk.jpg" alt="tobolsk"/> 
      <div><strong>tobolsk</strong><br>Green offset: (+3, +3)<br>Red offset: (+3, +6)</div> 
    </div>
  </section>

  <section>
    <h2>Multi-Scale Pyramid Alignment</h2>
    <p>
      To handle larger displacements efficiently, I implemented a pyramid search: start at low resolution for coarse alignment, then refine at higher resolutions. NCC is also used here, and the idea is similar: first pre-process the image (see bells&whistles section), then scale down the image by factor of 2 until it is smaller than 200*200 pixel. Then, within the [-15,15] pixel range, find the best alignment such that the NCC value is maximized. After that, use the 2x bigger image and find the best alignment within the [-1,1] range, as these are the only possible pixels after scaling up. Blue is used as a reference picture while green and red are moved with (x,y) pixels to align with blue.
    </p>
    <div class="result">
      <img src="output/emir.jpg" alt="emir"/>
      <div><strong>emir</strong><br>Green offset: (+23, +49)<br>Red offset: (+40, +107)</div>
    </div>
    <div class="result">
      <img src="output/church.jpg" alt="church"/>
      <div><strong>church</strong><br>Green offset: (+4, +25)<br>Red offset: (-4, +58)</div>
    </div>
    <div class="result">
      <img src="output/harvesters.jpg" alt="harvesters"/>
      <div><strong>harvesters</strong><br>Green offset: (+18, +60)<br>Red offset: (+11, +118)</div>
    </div>
    <div class="result">
      <img src="output/icon.jpg" alt="icon"/>
      <div><strong>icon</strong><br>Green offset: (+16, +38)<br>Red offset: (+22, +90)</div>
    </div>
    <div class="result">
      <img src="output/italil.jpg" alt="italil"/>
      <div><strong>italil</strong><br>Green offset: (+22, +38)<br>Red offset: (+36, +77)</div>
    </div>
    <div class="result">
      <img src="output/lastochikino.jpg" alt="lastochikino"/>
      <div><strong>lastochikino</strong><br>Green offset: (-2, -3)<br>Red offset: (-9, +76)</div>
    </div>
    <div class="result">
      <img src="output/lugano.jpg" alt="lugano"/>
      <div><strong>lugano</strong><br>Green offset: (-17, +41)<br>Red offset: (-29, +93)</div>
    </div>
    <div class="result">
      <img src="output/melons.jpg" alt="melons"/>
      <div><strong>melons</strong><br>Green offset: (+9, +79)<br>Red offset: (+13, +177)</div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="self_portrait"/>
      <div><strong>self_portrait</strong><br>Green offset: (+29, +77)<br>Red offset: (+37, +175)</div>
    </div>
    <div class="result">
      <img src="output/siren.jpg" alt="siren"/>
      <div><strong>siren</strong><br>Green offset: (-5, +48)<br>Red offset: (-23, +96)</div>
    </div>
    <div class="result">
      <img src="output/three_generations.jpg" alt="three_generations"/>
      <div><strong>three_generations</strong><br>Green offset: (+17, +57)<br>Red offset: (+12, +115)</div>
    </div>
  </section>

  <section>
    <h2>Bells & Whistles</h2>

    <h3>1. Automatic Contrasting</h3>
    <p>
      I remap pixel intensities so the darkest pixel becomes 0 and the brightest becomes 1. This enhances dynamic range and improves visibility, especially in underexposed or flat-looking images. The before and after comparison shows clear difference, thus this is an important feature.
    </p>
    <div class="result">
      <img src="output/self_portrait_no_contrast.jpg" alt="before contrast"/>
      <div><strong>Before contrast</strong></div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="after contrast"/>
      <div><strong>After contrast</strong></div>
    </div>

    <h3>2. Automatic White Balance</h3>
    <p>
      I apply the <em>gray-world assumption</em>: if the average of all colors should be gray, then scale each channel so its mean matches the global mean. This removes strong color casts (e.g., overly blue or yellow images). The result does not show huge difference, partially because of the lighting in this picture is already gray-world and the pixel value are distributed with a gray-world mean.
    </p>
    <div class="result">
      <img src="output/self_portrait_no_wb.jpg" alt="before wb"/>
      <div><strong>Before white balance</strong></div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="after wb"/>
      <div><strong>After white balance</strong></div>
    </div>

    <h3>3. Better Color Mapping</h3>
    <p>
      To normalize colors, I adjust each channel so the average intensity maps closer to a neutral gray. This reduces bias from one dominant channel and produces more natural-looking results. As shown in the result, before the color mapping, the image seems like it has a "vintage filter" on it. The color mapping successfully removed the "filter", making the picture more realistic.
    </p>
    <div class="result">
      <img src="output/self_portrait_no_cm.jpg" alt="before colormap"/>
      <div><strong>Before color mapping</strong></div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="after colormap"/>
      <div><strong>After color mapping</strong></div>
    </div>

    <h3>4. Automatic Cropping</h3>
    <p>
      Many plates have thick borders, numbers, or stains. I detect rows/columns with low variance or low mean intensity, compute bounding boxes for each channel, and take their intersection (IoU). This significantly reduces visible borders. However, it is not yet perfect, reasons are explained in the Failure Section below.
    </p>
    <div class="result">
      <img src="output/self_portrait_no_crop.jpg" alt="before crop"/>
      <div><strong>Before cropping</strong></div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="after crop"/>
      <div><strong>After cropping</strong></div>
    </div>

    <h3>5. Better Features (Canny Edges)</h3>
    <p>
      Instead of using raw pixel values with NCC, I align based on <strong>Canny edge maps</strong>. Edges are less sensitive to brightness differences and highlight structural details, making alignment more robust in cases where intensity differs between channels. In this case, both NCC and Canny filter worked perfectly, and the shift turned out to be the same :)
    </p>
    <div class="result">
      <img src="output/self_portrait_ncc.jpg" alt="harvesters edges"/>
      <div><strong>harvesters (edge features)</strong></div>
    </div>
    <div class="result">
      <img src="output/self_portrait.jpg" alt="icon edges"/>
      <div><strong>icon (edge features)</strong></div>
    </div>
  </section>

  <section>
    <h2>Problems & Failures</h2>
    <p>
      The biggest problem I encountered is border detection. I tried multiple methods: detect boarder based on variance, intensity, or gradient, and every combination between these three. However, no matter how hard I try, I cannot detect border perfectly for every image because of the noise on the border (some has numbers on the border, some has stains, etc.). The final approach is to use a mix of all three methods, find the border on each r,g and b image, then find the IoU region as the final result. Although borders are still visible on some images, borders are much smaller than without applying the algorithm.
    </p>
  </section>
</main>

<footer>
  <div>Joshua Sun · 280A Project 1</div>
</footer>
</body>
</html>